{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Excalibro1/zimwithloracolab/blob/main/Zimageturboloraqwenb8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Credit:\n",
        "[Z-Image Github](https://github.com/Tongyi-MAI/Z-Image) <br>\n",
        "Colab Code: [camenduru](https://github.com/camenduru/Z-Image-jupyter\n",
        "\n",
        "Edited code from camemduru and added lora support and downloads the qwen_3_4b.safetensors also the Qwen3-4B-abliterated.Q8_0.gguf with an option in the ui to switch between them"
      ],
      "metadata": {
        "id": "PROsUqH9x77h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîß Install Z-Image Turbo + GGUF (Drive + cache aware)\n",
        "import os, pathlib, subprocess, shutil\n",
        "\n",
        "print(\"üìå Starting Z-Image Turbo setup...\")\n",
        "\n",
        "############################\n",
        "# 0Ô∏è‚É£ Mount Drive EARLY\n",
        "############################\n",
        "from google.colab import drive\n",
        "if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "    print(\"üîå Mounting Google Drive...\")\n",
        "    drive.mount(\"/content/drive\")\n",
        "else:\n",
        "    print(\"üíæ Drive already mounted.\")\n",
        "\n",
        "############################\n",
        "# 1Ô∏è‚É£ Folder layout\n",
        "############################\n",
        "COMFY_ROOT = \"/content/ComfyUI\"\n",
        "CACHE_ROOT = \"/content/ZImage_ComfyUI_cache\"\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/ZImage_ComfyUI/models\"\n",
        "\n",
        "os.makedirs(CACHE_ROOT, exist_ok=True)\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "print(f\"üìÇ Cache folder:  {CACHE_ROOT}\")\n",
        "print(f\"üìÇ Drive folder:  {DRIVE_ROOT}\")\n",
        "\n",
        "# Base model subfolders (cache + Drive)\n",
        "base_subdirs = [\"diffusion_models\", \"clip\", \"vae\"]\n",
        "for s in base_subdirs:\n",
        "    os.makedirs(os.path.join(CACHE_ROOT, s), exist_ok=True)\n",
        "    os.makedirs(os.path.join(DRIVE_ROOT, s), exist_ok=True)\n",
        "\n",
        "# LoRAs live only on Drive\n",
        "os.makedirs(os.path.join(DRIVE_ROOT, \"loras\"), exist_ok=True)\n",
        "\n",
        "############################\n",
        "# 2Ô∏è‚É£ Install system + Python deps\n",
        "############################\n",
        "print(\"‚¨áÔ∏è Installing dependencies...\")\n",
        "%cd /content\n",
        "!apt -y install aria2\n",
        "\n",
        "# CUDA-matched PyTorch first\n",
        "!pip install torch==2.9.0+cu126 torchvision==0.24.0+cu126 torchaudio==2.9.0+cu126 --index-url https://download.pytorch.org/whl/cu126\n",
        "\n",
        "# Core runtime deps\n",
        "!pip install -q av==16.0.1 torchsde==0.2.6 safetensors pillow scipy tqdm einops transformers pyyaml aiohttp\n",
        "\n",
        "# ComfyUI supporting dependencies\n",
        "!pip install -q comfyui-frontend-package==1.33.13\n",
        "!pip install -q comfyui-workflow-templates==0.7.54\n",
        "!pip install -q comfyui-embedded-docs==0.3.1\n",
        "!pip install -q spandrel==0.4.1 SQLAlchemy==2.0.44\n",
        "!pip install -q pydantic==2.12.3 pydantic-settings==2.12.0\n",
        "\n",
        "############################\n",
        "# 3Ô∏è‚É£ Install / update ComfyUI backend\n",
        "############################\n",
        "if not os.path.exists(COMFY_ROOT):\n",
        "    print(\"‚¨áÔ∏è Cloning ComfyUI...\")\n",
        "    !git clone https://github.com/comfyanonymous/ComfyUI.git\n",
        "else:\n",
        "    print(\"‚úîÔ∏è ComfyUI already exists\")\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "# Make sure internal deps are installed too\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "############################\n",
        "# 4Ô∏è‚É£ Install / repair ComfyUI-GGUF nodes\n",
        "############################\n",
        "CUSTOM_NODES_ROOT = os.path.join(COMFY_ROOT, \"custom_nodes\")\n",
        "os.makedirs(CUSTOM_NODES_ROOT, exist_ok=True)\n",
        "%cd \"$CUSTOM_NODES_ROOT\"\n",
        "\n",
        "gguf_path = os.path.join(CUSTOM_NODES_ROOT, \"ComfyUI-GGUF\")\n",
        "\n",
        "# If folder exists but looks broken (no 'nodes' dir), reset it\n",
        "if os.path.exists(gguf_path) and not os.path.isdir(os.path.join(gguf_path, \"nodes\")):\n",
        "    print(\"‚ö†Ô∏è ComfyUI-GGUF folder looks corrupted ‚Üí resetting...\")\n",
        "    !rm -rf \"ComfyUI-GGUF\"\n",
        "\n",
        "if not os.path.exists(gguf_path):\n",
        "    print(\"‚¨áÔ∏è Installing ComfyUI-GGUF nodes...\")\n",
        "    !git clone https://github.com/city96/ComfyUI-GGUF.git\n",
        "    !pip install -q gguf\n",
        "else:\n",
        "    print(\"‚úîÔ∏è GGUF nodes already available\")\n",
        "\n",
        "############################\n",
        "# 5Ô∏è‚É£ Required model inventory\n",
        "############################\n",
        "required_files = {\n",
        "    \"diffusion_models\": {\n",
        "        \"z-image-turbo-fp8-e4m3fn.safetensors\":\n",
        "        \"https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors\"\n",
        "    },\n",
        "    \"clip\": {\n",
        "        # Standard CLIP\n",
        "        \"qwen_3_4b.safetensors\":\n",
        "        \"https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/qwen_3_4b.safetensors\",\n",
        "\n",
        "        # GGUF CLIP\n",
        "        \"Qwen3-4B-abliterated.Q8_0.gguf\":\n",
        "        \"https://huggingface.co/mradermacher/Qwen3-4B-abliterated-GGUF/resolve/main/Qwen3-4B-abliterated.Q8_0.gguf\"\n",
        "    },\n",
        "    \"vae\": {\n",
        "        \"ae.safetensors\":\n",
        "        \"https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/ae.safetensors\"\n",
        "    }\n",
        "}\n",
        "\n",
        "############################\n",
        "# 6Ô∏è‚É£ Smart copy + download into CACHE\n",
        "############################\n",
        "for subfolder, files in required_files.items():\n",
        "    print(f\"\\nüîé Checking {subfolder}...\")\n",
        "    drive_path = pathlib.Path(DRIVE_ROOT) / subfolder\n",
        "    cache_path = pathlib.Path(CACHE_ROOT) / subfolder\n",
        "\n",
        "    for filename, url in files.items():\n",
        "        src = drive_path / filename\n",
        "        dst = cache_path / filename\n",
        "\n",
        "        if dst.exists():\n",
        "            print(f\"‚úîÔ∏è Cache OK: {filename}\")\n",
        "            continue\n",
        "\n",
        "        if src.exists():\n",
        "            print(f\"üì• Copying from Drive ‚Üí Cache: {filename}\")\n",
        "            shutil.copy2(src, dst)\n",
        "            continue\n",
        "\n",
        "        print(f\"‚¨áÔ∏è Missing, downloading: {filename}\")\n",
        "        cmd = [\n",
        "            \"aria2c\", \"--console-log-level=error\", \"-c\",\n",
        "            \"-x\", \"16\", \"-s\", \"16\", \"-k\", \"1M\",\n",
        "            url, \"-d\", str(cache_path), \"-o\", filename\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "\n",
        "        if dst.exists():\n",
        "            print(f\"   ‚ûï Downloaded: {filename}\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå FAILED download: {filename}\")\n",
        "\n",
        "############################\n",
        "# 7Ô∏è‚É£ Summary\n",
        "############################\n",
        "print(\"\\nüéØ Setup complete! Final locations:\")\n",
        "print(f\"  Base models (CACHE) ‚Üí {CACHE_ROOT}\")\n",
        "print(f\"  LoRAs (DRIVE)       ‚Üí {DRIVE_ROOT}/loras\")\n",
        "\n",
        "print(\"\\nüìÅ Cache tree:\")\n",
        "for root, dirs, files in os.walk(CACHE_ROOT):\n",
        "    level = root.replace(CACHE_ROOT, \"\").count(os.sep)\n",
        "    indent = \"  \" * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = \"  \" * (level + 1)\n",
        "    for f in files:\n",
        "        print(f\"{subindent}{f}\")"
      ],
      "metadata": {
        "id": "nWezqa_wtcor",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñº Z-Image Turbo ‚Äì LoRA + optional GGUF CLIP (auto low-RAM, logs)\n",
        "import os, sys, gc, random, contextlib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import gradio as gr\n",
        "import requests  # üîπ for LoRA downloader\n",
        "\n",
        "COMFY_ROOT          = \"/content/ComfyUI\"\n",
        "BASE_CACHE          = \"/content/ZImage_ComfyUI_cache\"\n",
        "DRIVE_MODELS_ROOT   = \"/content/drive/MyDrive/ZImage_ComfyUI/models\"\n",
        "CACHE_DIFF_DIR      = os.path.join(BASE_CACHE, \"diffusion_models\")\n",
        "CACHE_CLIP_DIR      = os.path.join(BASE_CACHE, \"clip\")\n",
        "CACHE_VAE_DIR       = os.path.join(BASE_CACHE, \"vae\")\n",
        "DRIVE_LORAS_DIR     = os.path.join(DRIVE_MODELS_ROOT, \"loras\")\n",
        "os.makedirs(DRIVE_LORAS_DIR, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(os.path.join(COMFY_ROOT, \"folder_paths.py\")):\n",
        "    raise RuntimeError(\"‚ùå ComfyUI not found ‚Äî run the install cell first.\")\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "if COMFY_ROOT not in sys.path:\n",
        "    sys.path.append(COMFY_ROOT)\n",
        "CUSTOM_NODES_ROOT = os.path.join(COMFY_ROOT, \"custom_nodes\")\n",
        "if CUSTOM_NODES_ROOT not in sys.path:\n",
        "    sys.path.append(CUSTOM_NODES_ROOT)\n",
        "\n",
        "GGUF_SRC   = os.path.join(CUSTOM_NODES_ROOT, \"ComfyUI-GGUF\")\n",
        "GGUF_ALIAS = os.path.join(CUSTOM_NODES_ROOT, \"ComfyUI_GGUF\")\n",
        "\n",
        "if os.path.isdir(GGUF_SRC) and not os.path.exists(GGUF_ALIAS):\n",
        "    try:\n",
        "        os.symlink(GGUF_SRC, GGUF_ALIAS)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "\n",
        "import folder_paths\n",
        "from nodes import (\n",
        "    UNETLoader, CLIPLoader, VAELoader,\n",
        "    CLIPTextEncode, KSampler, EmptyLatentImage, VAEDecode,\n",
        "    LoraLoader,\n",
        ")\n",
        "import comfy.model_management as mm\n",
        "\n",
        "HAS_GGUF = False\n",
        "try:\n",
        "    from ComfyUI_GGUF.nodes import CLIPLoaderGGUF\n",
        "    HAS_GGUF = True\n",
        "    print(\"‚úÖ GGUF CLIPLoaderGGUF available\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è GGUF CLIP not available:\", e)\n",
        "\n",
        "folder_paths.add_model_folder_path(\"diffusion_models\", CACHE_DIFF_DIR)\n",
        "folder_paths.add_model_folder_path(\"clip\", CACHE_CLIP_DIR)\n",
        "folder_paths.add_model_folder_path(\"text_encoders\", CACHE_CLIP_DIR)\n",
        "folder_paths.add_model_folder_path(\"vae\", CACHE_VAE_DIR)\n",
        "folder_paths.add_model_folder_path(\"loras\", DRIVE_LORAS_DIR)\n",
        "\n",
        "get_dev = getattr(mm, \"get_torch_device\", None)\n",
        "DEFAULT_DEVICE = get_dev() if callable(get_dev) else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"üñ• Default device:\", DEFAULT_DEVICE)\n",
        "\n",
        "def hard_cleanup_models(log=None):\n",
        "    for name in (\"unload_all_loras\", \"cleanup_models\", \"unload_all_models\", \"soft_empty_cache\"):\n",
        "        fn = getattr(mm, name, None)\n",
        "        if callable(fn):\n",
        "            try:\n",
        "                fn()\n",
        "                if log:\n",
        "                    log(f\"üß† {name}()\")\n",
        "            except Exception as e:\n",
        "                if log:\n",
        "                    log(f\"‚ö†Ô∏è {name} failed: {e}\")\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def list_loras():\n",
        "    try:\n",
        "        files = folder_paths.get_filename_list(\"loras\")\n",
        "        files = [f for f in files if f.lower().endswith(\".safetensors\")]\n",
        "    except Exception:\n",
        "        if not os.path.isdir(DRIVE_LORAS_DIR):\n",
        "            return [\"<none>\"]\n",
        "        files = [f for f in os.listdir(DRIVE_LORAS_DIR) if f.lower().endswith(\".safetensors\")]\n",
        "    return [\"<none>\"] + sorted(files)\n",
        "\n",
        "def scan_clip_files(use_gguf):\n",
        "    if not os.path.isdir(CACHE_CLIP_DIR):\n",
        "        return []\n",
        "    exts = (\".gguf\",) if use_gguf else (\".safetensors\",)\n",
        "    files = [f for f in os.listdir(CACHE_CLIP_DIR) if f.lower().endswith(exts)]\n",
        "    return sorted(files)\n",
        "\n",
        "def update_clip_choices(use_gguf):\n",
        "    files = scan_clip_files(use_gguf)\n",
        "    if not files:\n",
        "        return gr.update(choices=[], value=None)\n",
        "    default = \"qwen_3_4b.safetensors\" if not use_gguf and \"qwen_3_4b.safetensors\" in files else files[0]\n",
        "    return gr.update(choices=files, value=default)\n",
        "\n",
        "# üîª NEW: LoRA downloader helper\n",
        "def download_lora_from_ui(url, filename, hf_token, civitai_token):\n",
        "    logs = []\n",
        "    def log(msg):\n",
        "        msg = str(msg)\n",
        "        logs.append(msg)\n",
        "        print(msg)\n",
        "\n",
        "    url = (url or \"\").strip()\n",
        "    filename = (filename or \"\").strip()\n",
        "    hf_token = (hf_token or \"\").strip()\n",
        "    civitai_token = (civitai_token or \"\").strip()\n",
        "\n",
        "    if not url:\n",
        "        log(\"‚ùå No URL provided.\")\n",
        "        return gr.update(choices=list_loras(), value=\"<none>\"), \"\\n\".join(logs)\n",
        "\n",
        "    # Guess filename from URL if missing\n",
        "    if not filename:\n",
        "        base = os.path.basename(url.split(\"?\")[0])\n",
        "        if base:\n",
        "            filename = base\n",
        "        else:\n",
        "            filename = \"lora_download.safetensors\"\n",
        "\n",
        "    # Ensure .safetensors\n",
        "    if not filename.lower().endswith(\".safetensors\"):\n",
        "        filename += \".safetensors\"\n",
        "\n",
        "    dest = os.path.join(DRIVE_LORAS_DIR, filename)\n",
        "    os.makedirs(DRIVE_LORAS_DIR, exist_ok=True)\n",
        "\n",
        "    log(f\"üìÅ LoRA save path: {dest}\")\n",
        "\n",
        "    if os.path.exists(dest):\n",
        "        log(\"‚ÑπÔ∏è File already exists, overwriting...\")\n",
        "\n",
        "    headers = {}\n",
        "    lower_url = url.lower()\n",
        "\n",
        "    if \"huggingface.co\" in lower_url and hf_token:\n",
        "        headers[\"Authorization\"] = f\"Bearer {hf_token}\"\n",
        "        log(\"üîê Using HuggingFace token.\")\n",
        "\n",
        "    if \"civitai.com\" in lower_url and civitai_token:\n",
        "        # Civitai supports Authorization bearer; some tools also use X-Api-Key\n",
        "        headers[\"Authorization\"] = f\"Bearer {civitai_token}\"\n",
        "        headers[\"X-Api-Key\"] = civitai_token\n",
        "        log(\"üîê Using Civitai token.\")\n",
        "\n",
        "    try:\n",
        "        log(\"‚¨áÔ∏è Downloading LoRA...\")\n",
        "        with requests.get(url, headers=headers, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(dest, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "        log(\"‚úÖ Download complete.\")\n",
        "    except Exception as e:\n",
        "        log(f\"‚ùå Download failed: {e}\")\n",
        "        # Refresh list anyway\n",
        "        return gr.update(choices=list_loras(), value=\"<none>\"), \"\\n\".join(logs)\n",
        "\n",
        "    # Refresh dropdown ‚Üí select the newly downloaded file\n",
        "    loras = list_loras()\n",
        "    new_value = filename if filename in loras else \"<none>\"\n",
        "    return gr.update(choices=loras, value=new_value), \"\\n\".join(logs)\n",
        "\n",
        "def generate_image(\n",
        "    prompt, negative, steps, cfg,\n",
        "    sampler_name, scheduler,\n",
        "    width, height, seed,\n",
        "    use_lora, selected_lora,\n",
        "    lora_strength_model, lora_strength_clip,\n",
        "    use_gguf_clip, selected_clip_name,\n",
        "):\n",
        "    logs = []\n",
        "    def log(x):\n",
        "        x = str(x)\n",
        "        logs.append(x)\n",
        "        print(x)\n",
        "\n",
        "    if not prompt or not prompt.strip():\n",
        "        log(\"‚ùå Empty prompt\")\n",
        "        return [], \"\\n\".join(logs)\n",
        "\n",
        "    # Seed\n",
        "    seed = int(seed if seed and seed >= 0 else random.randint(0, 2**31 - 1))\n",
        "    torch.manual_seed(seed)\n",
        "    log(f\"üî¢ Seed: {seed}\")\n",
        "\n",
        "    run_device = DEFAULT_DEVICE\n",
        "    use_cuda = (run_device == \"cuda\" and torch.cuda.is_available())\n",
        "    log(f\"üß† Device: {run_device} | GGUF CLIP: {use_gguf_clip}\")\n",
        "\n",
        "    # Load UNet\n",
        "    try:\n",
        "        log(\"üì¶ Loading UNet...\")\n",
        "        unet = UNETLoader().load_unet(\n",
        "            \"z-image-turbo-fp8-e4m3fn.safetensors\",\n",
        "            \"fp8_e4m3fn_fast\"\n",
        "        )[0]\n",
        "        log(\"‚úÖ UNet ready\")\n",
        "    except Exception as e:\n",
        "        log(f\"UNet error: {e}\")\n",
        "        hard_cleanup_models(log)\n",
        "        return [], \"\\n\".join(logs)\n",
        "\n",
        "    # Load CLIP\n",
        "    try:\n",
        "        if not selected_clip_name:\n",
        "            files = scan_clip_files(use_gguf_clip)\n",
        "            if not files:\n",
        "                raise RuntimeError(\"No CLIP models found in cache.\")\n",
        "            selected_clip_name = files[0]\n",
        "\n",
        "        if use_gguf_clip:\n",
        "            if not HAS_GGUF:\n",
        "                raise RuntimeError(\"GGUF requested but CLIPLoaderGGUF not available.\")\n",
        "            log(f\"üì¶ Loading GGUF CLIP: {selected_clip_name}\")\n",
        "            clip = CLIPLoaderGGUF().load_clip(selected_clip_name)[0]\n",
        "        else:\n",
        "            log(f\"üì¶ Loading CLIP: {selected_clip_name}\")\n",
        "            clip = CLIPLoader().load_clip(selected_clip_name, \"ltxv\")[0]\n",
        "\n",
        "        log(\"‚úÖ CLIP ready\")\n",
        "    except Exception as e:\n",
        "        log(f\"CLIP error: {e}\")\n",
        "        try:\n",
        "            del unet\n",
        "        except Exception:\n",
        "            pass\n",
        "        hard_cleanup_models(log)\n",
        "        return [], \"\\n\".join(logs)\n",
        "\n",
        "    # LoRA\n",
        "    if use_lora and selected_lora not in (\"<none>\", None, \"\"):\n",
        "        try:\n",
        "            log(f\"üéØ Applying LoRA: {selected_lora} \"\n",
        "                f\"(model={lora_strength_model}, clip={lora_strength_clip})\")\n",
        "            unet, clip = LoraLoader().load_lora(\n",
        "                unet, clip, selected_lora,\n",
        "                float(lora_strength_model), float(lora_strength_clip)\n",
        "            )\n",
        "            log(\"‚úÖ LoRA applied.\")\n",
        "        except Exception as e:\n",
        "            log(f\"‚ö†Ô∏è LoRA failed: {e}\")\n",
        "\n",
        "    # Encode prompts\n",
        "    try:\n",
        "        log(\"‚úè Encoding text...\")\n",
        "        pos = CLIPTextEncode().encode(clip, prompt)[0]\n",
        "        neg = CLIPTextEncode().encode(clip, negative or \"\")[0]\n",
        "    except Exception as e:\n",
        "        log(f\"‚ùå Text encoding failed: {e}\")\n",
        "        try:\n",
        "            del unet, clip\n",
        "        except Exception:\n",
        "            pass\n",
        "        hard_cleanup_models(log)\n",
        "        return [], \"\\n\".join(logs)\n",
        "\n",
        "    # Drop CLIP early\n",
        "    try:\n",
        "        del clip\n",
        "    except Exception:\n",
        "        pass\n",
        "    gc.collect()\n",
        "    if use_cuda:\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Latent\n",
        "    log(f\"üåå Latent: {width}√ó{height}\")\n",
        "    latent = EmptyLatentImage().generate(int(width), int(height), 1)[0]\n",
        "\n",
        "    # Sampling\n",
        "    log(f\"‚è≥ Sampling {int(steps)} steps cfg={float(cfg)}\")\n",
        "    try:\n",
        "        ctx = torch.autocast(\"cuda\") if use_cuda else contextlib.nullcontext()\n",
        "        with torch.inference_mode(), ctx:\n",
        "            samples = KSampler().sample(\n",
        "                model=unet, seed=seed, steps=int(steps), cfg=float(cfg),\n",
        "                sampler_name=sampler_name, scheduler=scheduler,\n",
        "                positive=pos, negative=neg,\n",
        "                latent_image=latent, denoise=1.0\n",
        "            )[0]\n",
        "    except Exception as e:\n",
        "        log(f\"Sampling failed: {e}\")\n",
        "        try:\n",
        "            del unet, pos, neg, latent\n",
        "        except Exception:\n",
        "            pass\n",
        "        hard_cleanup_models(log)\n",
        "        return [], \"\\n\".join(logs)\n",
        "\n",
        "    try:\n",
        "        del unet, pos, neg, latent\n",
        "    except Exception:\n",
        "        pass\n",
        "    gc.collect()\n",
        "    if use_cuda:\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Decode\n",
        "    try:\n",
        "        log(\"üì¶ Loading VAE...\")\n",
        "        vae = VAELoader().load_vae(\"ae.safetensors\")[0]\n",
        "        log(\"üñº Decoding...\")\n",
        "        ctx = torch.autocast(\"cuda\") if use_cuda else contextlib.nullcontext()\n",
        "        with torch.inference_mode(), ctx:\n",
        "            decoded = VAEDecode().decode(vae, samples)[0]\n",
        "    except Exception as e:\n",
        "        log(f\"Decode failed: {e}\")\n",
        "        try:\n",
        "            del vae, samples\n",
        "        except Exception:\n",
        "            pass\n",
        "        hard_cleanup_models(log)\n",
        "        return [], \"\\n\".join(logs)\n",
        "\n",
        "    log(\"üß© Converting to images...\")\n",
        "    arr = decoded.cpu().numpy()\n",
        "    images = []\n",
        "    for i in range(arr.shape[0]):\n",
        "        img = (np.clip(arr[i], 0.0, 1.0) * 255).astype(np.uint8)\n",
        "        images.append(Image.fromarray(img))\n",
        "\n",
        "    try:\n",
        "        del vae, samples, decoded, arr\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    log(\"üßπ Cleanup...\")\n",
        "    hard_cleanup_models(log)\n",
        "    log(\"‚úÖ Done.\")\n",
        "    return images, \"\\n\".join(logs)\n",
        "\n",
        "\n",
        "# UI ------------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üñº Z-Image Turbo ‚Äì LoRA + optional GGUF CLIP\")\n",
        "\n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(\n",
        "            label=\"Prompt\",\n",
        "            value=\"A detailed 512x512 illustration of a neon cyberpunk forest city at dusk\",\n",
        "            lines=3,\n",
        "        )\n",
        "        negative = gr.Textbox(\n",
        "            label=\"Negative prompt\",\n",
        "            value=\"low quality, blurry, distorted, watermark\",\n",
        "            lines=3,\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        steps = gr.Slider(1, 32, 8, step=1, label=\"Steps\")\n",
        "        cfg   = gr.Slider(0.0, 4.0, 1.0, step=0.1, label=\"CFG\")\n",
        "\n",
        "    with gr.Row():\n",
        "        sampler_name = gr.Dropdown(\n",
        "            [\"euler_ancestral\", \"euler\", \"dpmpp_2m\"],\n",
        "            value=\"euler\",\n",
        "            label=\"Sampler\",\n",
        "        )\n",
        "        scheduler = gr.Dropdown(\n",
        "            [\"normal\", \"karras\"],\n",
        "            value=\"normal\",\n",
        "            label=\"Scheduler\",\n",
        "        )\n",
        "        seed = gr.Number(-1, label=\"Seed (-1 = random)\")\n",
        "\n",
        "    # 1024 max res\n",
        "    with gr.Row():\n",
        "        width  = gr.Slider(256, 1024, 512, step=8, label=\"Width\")\n",
        "        height = gr.Slider(256, 1024, 512, step=8, label=\"Height\")\n",
        "\n",
        "    gr.Markdown(\"### CLIP / Text Encoder\")\n",
        "    with gr.Row():\n",
        "        use_gguf_clip = gr.Checkbox(False, label=\"Use GGUF CLIP\")\n",
        "        initial_clip_choices = scan_clip_files(False)\n",
        "        initial_clip_value = \"qwen_3_4b.safetensors\" if \"qwen_3_4b.safetensors\" in initial_clip_choices else (initial_clip_choices[0] if initial_clip_choices else None)\n",
        "        clip_dropdown = gr.Dropdown(\n",
        "            choices=initial_clip_choices,\n",
        "            value=initial_clip_value,\n",
        "            label=\"CLIP model file\",\n",
        "        )\n",
        "    use_gguf_clip.change(update_clip_choices, [use_gguf_clip], [clip_dropdown])\n",
        "\n",
        "    gr.Markdown(\"### LoRA\")\n",
        "    with gr.Row():\n",
        "        use_lora = gr.Checkbox(False, label=\"Enable LoRA\")\n",
        "        lora_dropdown = gr.Dropdown(\n",
        "            choices=list_loras(),\n",
        "            value=\"<none>\",\n",
        "            label=\"LoRA file (from Drive loras folder)\",\n",
        "        )\n",
        "        refresh_loras_btn = gr.Button(\"üîÑ Refresh LoRA list\")\n",
        "\n",
        "    def refresh_loras():\n",
        "        return gr.update(choices=list_loras(), value=\"<none>\")\n",
        "\n",
        "    refresh_loras_btn.click(\n",
        "        fn=refresh_loras,\n",
        "        inputs=[],\n",
        "        outputs=[lora_dropdown],\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        lora_strength_model = gr.Slider(-2.0, 2.0, 1.0, step=0.1, label=\"LoRA Model (UNet) weight\")\n",
        "        lora_strength_clip  = gr.Slider(-2.0, 2.0, 0.0, step=0.1, label=\"LoRA CLIP weight (0 = UNet only)\")\n",
        "\n",
        "    # üîª NEW: LoRA Downloader UI\n",
        "    gr.Markdown(\"### ‚¨áÔ∏è LoRA Downloader (HuggingFace / Civitai)\")\n",
        "    with gr.Row():\n",
        "        lora_url = gr.Textbox(\n",
        "            label=\"LoRA URL (HuggingFace/Civitai direct download link)\",\n",
        "            placeholder=\"https://civitai.com/api/download/models/...\")\n",
        "    with gr.Row():\n",
        "        lora_filename = gr.Textbox(\n",
        "            label=\"Save as (optional, .safetensors will be added if missing)\",\n",
        "            placeholder=\"my_lora_name\"\n",
        "        )\n",
        "    with gr.Row():\n",
        "        hf_token = gr.Textbox(\n",
        "            label=\"HuggingFace token (optional)\",\n",
        "            type=\"password\",\n",
        "            placeholder=\"hf_...\"\n",
        "        )\n",
        "        civitai_token = gr.Textbox(\n",
        "            label=\"Civitai API token (optional)\",\n",
        "            type=\"password\",\n",
        "            placeholder=\"civitai token...\"\n",
        "        )\n",
        "\n",
        "    download_lora_btn = gr.Button(\"‚¨áÔ∏è Download LoRA to Drive\")\n",
        "    lora_dl_log = gr.Textbox(\n",
        "        label=\"LoRA Downloader Log\",\n",
        "        lines=6,\n",
        "        interactive=False,\n",
        "    )\n",
        "\n",
        "    download_lora_btn.click(\n",
        "        fn=download_lora_from_ui,\n",
        "        inputs=[lora_url, lora_filename, hf_token, civitai_token],\n",
        "        outputs=[lora_dropdown, lora_dl_log],\n",
        "    )\n",
        "\n",
        "    run_btn = gr.Button(\"Generate üé®\")\n",
        "    gallery = gr.Gallery(\n",
        "        label=\"Result\",\n",
        "        height=512,\n",
        "        columns=2,\n",
        "    )\n",
        "    log_box = gr.Textbox(\n",
        "        label=\"Generation Logs\",\n",
        "        lines=16,\n",
        "        interactive=False,\n",
        "    )\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=generate_image,\n",
        "        inputs=[\n",
        "            prompt, negative,\n",
        "            steps, cfg,\n",
        "            sampler_name, scheduler,\n",
        "            width, height,\n",
        "            seed,\n",
        "            use_lora, lora_dropdown,\n",
        "            lora_strength_model, lora_strength_clip,\n",
        "            use_gguf_clip, clip_dropdown,\n",
        "        ],\n",
        "        outputs=[gallery, log_box],\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "LV4jH3Yctw3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}